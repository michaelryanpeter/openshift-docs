// Module included in the following assemblies:
// * scalability_and_performance/ztp-image-based-upgrade.adoc

:_mod-docs-content-type: PROCEDURE
[id="cnf-image-based-upgrade-creating-backup-resources_{context}"]
= Creating ConfigMap objects for the image-based upgrade with {lcao}

The {lcao} needs all your OADP resources, extra manifests, and custom catalog sources wrapped in a `ConfigMap` object to process them for the image-based upgrade.


[id="cnf-image-based-upgrade-creating-backup-oadp-resources_{context}"]
== Creating OADP ConfigMap objects for the image-based upgrade with {lcao}

Create your OADP resources that are used to back up and restore your resources during the upgrade.

.Prerequisites

* Generate a seed image from a compatible seed cluster.
* Create backup and restore resources.
* Create a separate partition on the target cluster for the container images that is shared between stateroots. For more information about, see _Additional resources_.
* Deploy a version of {lcao} that is compatible with the version used with the seed image.
* Install the OADP Operator, the `DataProtectionApplication` CR and its secret on the target cluster.
* Create an S3-compatible storage solution and a ready-to-use bucket with proper credentials configured. For more information, see _Additional resources_.

.Procedure

. Create your OADP `Backup` and `Restore` CRs in the same namespace where the OADP Operator is installed, which is `openshift-adp`.

. Filter for backup-specific CRs by using the `lca.openshift.io/apply-label` annotation in your `Backup` CRs. Based on which resources you define in the annotation, the {lcao} applies the `lca.openshift.io/backup: <backup_name>` label and adds the `labelSelector.matchLabels.lca.openshift.io/backup: <backup_name>` label selector to the specified resources when creating the `Backup` CRs.
+
--
[source,yaml]
----
apiVersion: velero.io/v1
kind: Backup
metadata:
  name: backup-acm-klusterlet <1>
  annotations:
    lca.openshift.io/apply-label: "apps/v1/deployments/open-cluster-management-agent/klusterlet,v1/secrets/open-cluster-management-agent/bootstrap-hub-kubeconfig,rbac.authorization.k8s.io/v1/clusterroles/klusterlet,v1/serviceaccounts/open-cluster-management-agent/klusterlet,scheduling.k8s.io/v1/priorityclasses/klusterlet-critical,rbac.authorization.k8s.io/v1/clusterroles/open-cluster-management:klusterlet-admin-aggregate-clusterrole,rbac.authorization.k8s.io/v1/clusterrolebindings/klusterlet,operator.open-cluster-management.io/v1/klusterlets/klusterlet,apiextensions.k8s.io/v1/customresourcedefinitions/klusterlets.operator.open-cluster-management.io,v1/secrets/open-cluster-management-agent/open-cluster-management-image-pull-credentials" <2>
  labels:
    velero.io/storage-location: default
  namespace: openshift-adp
spec:
  includedNamespaces:
  - open-cluster-management-agent
  includedClusterScopedResources:
  - klusterlets.operator.open-cluster-management.io
  - clusterroles.rbac.authorization.k8s.io
  - clusterrolebindings.rbac.authorization.k8s.io
  - priorityclasses.scheduling.k8s.io
  includedNamespaceScopedResources:
  - deployments
  - serviceaccounts
  - secrets
----
<1> The `acm-klusterlet` `Backup` and `Restore` CRs are specific to {rh-rhacm} environments only.
<2> The value must be a list of comma-separated objects in the `group/version/resource/name` format for cluster-scoped resources, or in the `group/version/resource/namespace/name` format for namespace-scoped resources. It must be attached to the related `Backup` CR.

[source,yaml]
----
apiVersion: velero.io/v1
kind: Backup
metadata:
  labels:
    velero.io/storage-location: default
  name: backup-example-app
  namespace: openshift-adp
spec:
  includedNamespaces:
  - test
  includedNamespaceScopedResources:
  - secrets
  - persistentvolumeclaims
  - deployments
  - statefulsets
  excludedClusterScopedResources:
  - persistentVolumes
----

[source,yaml]
----
apiVersion: velero.io/v1
kind: Restore
metadata:
  name: restore-acm-klusterlet <1>
  namespace: openshift-adp
  labels:
    velero.io/storage-location: default
  annotations:
    lca.openshift.io/apply-wave: "1"
spec:
  backupName:
    backup-acm-klusterlet
----
<1> The `acm-klusterlet` `Backup` and `Restore` CRs are specific to {rh-rhacm} environments only.

[source,yaml]
----
apiVersion: velero.io/v1
kind: Restore
metadata:
  name: restore-example-app
  namespace: openshift-adp
  labels:
    velero.io/storage-location: default
  annotations:
    lca.openshift.io/apply-wave: "2"
spec:
  backupName:
    backup-example-app
----

[NOTE]
====
Depending on your {rh-rhacm} configuration, you might need to include the `v1/secrets/open-cluster-management-agent/open-cluster-management-image-pull-credentials` object for backup. If your `multiclusterHub` CR has `.spec.imagePullSecret` defined and the secret exists on the `open-cluster-management-agent` namespace in your hub cluster, ensure that the object is included in the `lca.openshift.io/apply-label` annotation. If the secret does not exist, you can remove the object from the apply-label annotation.
====

[IMPORTANT]
====
To use the `lca.openshift.io/apply-label` annotation for backing up specific resources, the resources listed in the annotation should also be included in the `spec` section.
If the `lca.openshift.io/apply-label` annotation is used in the `Backup` CR, only the resources listed in the annotation will be backed up, even if other resource types are specified in the `spec` section or not.
====
--

. (Optional) If you created persistent volumes on your cluster through {lvms}, create your OADP resources for {lvms}.
+
[source,yaml]
----
apiVersion: velero.io/v1
kind: Backup
metadata:
  labels:
    velero.io/storage-location: default
  name: backup-example-lvmcluster
  namespace: openshift-adp
spec:
  includedNamespaces:
    - openshift-storage
  includedNamespaceScopedResources:
    - lvmclusters
    - lvmvolumegroups
    - lvmvolumegroupnodestatuses
---
apiVersion: velero.io/v1
kind: Restore
metadata:
  name: restore-example-lvmcluster
  namespace: openshift-adp
  labels:
    velero.io/storage-location: default
  annotations:
    lca.openshift.io/apply-wave: "2"
spec:
  backupName:
    backup-example-lvmcluster
----

.. You need to add certain fields to your application `Backup` and `Restore` CRs to ensure that each persistent volume is maintained through the upgrade.
+
[source,yaml]
----
apiVersion: velero.io/v1
kind: Backup
metadata:
  labels:
    velero.io/storage-location: default
  name: backup-example-app-lvms
  namespace: openshift-adp
spec:
  includedNamespaces:
  - test
  includedNamespaceScopedResources:
  - secrets
  - persistentvolumeclaims
  - deployments
  - statefulsets
  includedClusterScopedResources:
  - persistentVolumes
  - volumesnapshotcontents
  - logicalvolumes.topolvm.io
---
apiVersion: velero.io/v1
kind: Restore
metadata:
  name: restore-example-app-lvms
  namespace: openshift-adp
  labels:
    velero.io/storage-location: default
  annotations:
    lca.openshift.io/apply-wave: "3"
spec:
  backupName:
    backup-example-app-lvms
  restorePVs: true
  restoreStatus:
    includedResources:
      - logicalvolumes
----

. Define the apply order for the OADP Operator in the `Restore` CRs by using the `lca.openshift.io/apply-wave` field:
+
--
.Example OADP CRs without logical volumes
[source,yaml]
----
apiVersion: velero.io/v1
kind: Backup
metadata:
  labels:
    velero.io/storage-location: default
  name: backup-example-app
  namespace: openshift-adp
spec:
  includedNamespaces:
  - test
  includedNamespaceScopedResources:
  - secrets
  - persistentvolumeclaims
  - deployments
  - statefulsets
  excludedClusterScopedResources:
  - persistentVolumes
---
apiVersion: velero.io/v1
kind: Restore
metadata:
  name: restore-acm-klusterlet
  namespace: openshift-adp
  labels:
    velero.io/storage-location: default
  annotations:
    lca.openshift.io/apply-wave: "1"
spec:
  backupName:
    backup-acm-klusterlet
---
apiVersion: velero.io/v1
kind: Restore
metadata:
  name: restore-example-app
  namespace: openshift-adp
  labels:
    velero.io/storage-location: default
  annotations:
    lca.openshift.io/apply-wave: "2"
spec:
  backupName:
    backup-example-app
----

.Example OADP CRs with logical volumes
[source,yaml]
----
apiVersion: velero.io/v1
kind: Backup
metadata:
  labels:
    velero.io/storage-location: default
  name: backup-example-app-lvms
  namespace: openshift-adp
spec:
  includedNamespaces:
  - test
  includedNamespaceScopedResources:
  - secrets
  - persistentvolumeclaims
  - deployments
  - statefulsets
  includedClusterScopedResources:
  - persistentVolumes
  - volumesnapshotcontents
  - logicalvolumes.topolvm.io
---
apiVersion: velero.io/v1
kind: Restore
metadata:
  name: restore-example-lvmcluster
  namespace: openshift-adp
  labels:
    velero.io/storage-location: default
  annotations:
    lca.openshift.io/apply-wave: "2" <1>
spec:
  backupName:
    backup-example-lvmcluster
---
apiVersion: velero.io/v1
kind: Restore
metadata:
  name: restore-example-app-lvms
  namespace: openshift-adp
  labels:
    velero.io/storage-location: default
  annotations:
    lca.openshift.io/apply-wave: "3" <3>
spec:
  backupName:
    backup-example-app-lvms
  restorePVs: true
  restoreStatus:
    includedResources:
      - logicalvolumes
----
<1> Ensure that the `lca.openshift.io/apply-wave` annotation is numerically lower in your {lvms} `Backup` and `Restore` CRs than that of the application so that they are restored before your applications.

[NOTE]
====
If you do not define the `lca.openshift.io/apply-wave` annotation in the `Restore` CRs, they will be applied together.
====
--

. Generate a `ConfigMap` object for your OADP CRs.

.. Create the `ConfigMap` object:
+
[source,terminal]
----
$ oc create configmap example-oadp-cm --from-file=example-oadp-resources.yaml=<path_to_oadp_crs> -n openshift-adp
----

. Patch the `ImageBasedUpgrade` CR:
+
[source,terminal]
----
$ oc patch imagebasedupgrades.lca.openshift.io upgrade \
-p='{"spec": {"oadpContent": [{"name": "oadp-cm-example", "namespace": "openshift-adp"}]}}' \
--type=merge -n openshift-lifecycle-agent
----

[id="cnf-image-based-upgrade-creating-backup-extra-manifests_{context}"]
== (Optional) Creating ConfigMap objects of extra manifests for the image-based upgrade with {lcao}

Create your additional manifests that you want to apply to the target cluster.

.Procedure

. Create a YAML file that contains your extra manifests.
+
[source,yaml]
----
apiVersion: sriovnetwork.openshift.io/v1
kind: SriovNetworkNodePolicy
metadata:
  name: "pci-sriov-net-e5l"
  namespace: openshift-sriov-network-operator
spec:
  deviceType: vfio-pci
  isRdma: false
  nicSelector:
    pfNames: [ens1f0]
  nodeSelector:
    node-role.kubernetes.io/master: ""
  mtu: 1500
  numVfs: 8
  priority: 99
  resourceName: pci_sriov_net_e5l
---
apiVersion: sriovnetwork.openshift.io/v1
kind: SriovNetwork
metadata:
  name: "networking-e5l"
  namespace: openshift-sriov-network-operator
spec:
  ipam: |-
    {
    }
  linkState: auto
  networkNamespace: sriov-namespace
  resourceName: pci_sriov_net_e5l
  spoofChk: "on"
  trust: "off"
----

. Create the `ConfigMap` object:
+
[source,terminal]
----
$ oc create configmap example-extra-manifests-cm --from-file=example-extra-manifests.yaml=<path_to_extramanifest> -n openshift-lifecycle-agent
----

. Patch the `ImageBasedUpgrade` CR:
+
[source,terminal]
----
$ oc patch imagebasedupgrades.lca.openshift.io upgrade \
-p='{"spec": {"extraManifests": [{"name": "example-extra-manifests-cm", "namespace": "openshift-lifecycle-agent"}]}}' \
--type=merge -n openshift-lifecycle-agent
----

[id="cnf-image-based-upgrade-creating-backup-custom-catalog-sources_{context}"]
== (Optional) Creating ConfigMap objects of custom catalog sources for the image-based upgrade with {lcao}

You can keep your custom catalog sources after the upgrade by generating a `ConfigMap` object for your catalog sources and adding them to the `spec.extraManifest` field in the `ImageBasedUpgrade` CR.
For more information about catalog sources, see xref:https://access.redhat.com/documentation/en-us/openshift_container_platform/4.15/html-single/operators/index#olm-catalogsource_olm-understanding-olm[Catalog source].

.Procedure

. Create a YAML file that contains the `CatalogSource` CR.
+
--
[source,yaml]
----
apiVersion: operators.coreos.com/v1
kind: CatalogSource
metadata:
  name: example-catalogsources
  namespace: openshift-marketplace
spec:
  sourceType: grpc
  displayName: disconnected-redhat-operators
  image: quay.io/example-org/example-catalog:v1
----
--

. Create the `ConfigMap` object:
+
[source,terminal]
----
$ oc create configmap example-catalogsources-cm --from-file=example-catalogsources.yaml=<path_to_catalogsource_cr> -n openshift-lifecycle-agent
----

. Patch the `ImageBasedUpgrade` CR:
+
[source,terminal]
----
$ oc patch imagebasedupgrades.lca.openshift.io upgrade \
-p='{"spec": {"extraManifests": [{"name": "example-catalogsources-cm", "namespace": "openshift-lifecycle-agent"}]}}' \
--type=merge -n openshift-lifecycle-agent
----

To use the `ConfigMap` objects in the upgrade, see the _Performing an image-based upgrade with {lcao}_ section.